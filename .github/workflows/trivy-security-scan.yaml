name: Trivy Security Scan

on:
  schedule:
    # Run on the first Sunday of every month at 2:00 AM UTC
    - cron: "0 2 1-7 * 0"
  workflow_dispatch:
    # Allow manual triggering of the workflow
    inputs:
      debug_mode:
        description: "Enable debug mode for troubleshooting"
        required: false
        default: false
        type: boolean
      force_fresh_scan:
        description: "Force fresh scan even if recent results are available"
        required: false
        default: false
        type: boolean
      disable_recent_check:
        description: "Disable recent scan checking (always do fresh scan)"
        required: false
        default: false
        type: boolean
      resume_from_progress:
        description: "Resume from previous scan progress (if available)"
        required: false
        default: true
        type: boolean
      skip_to_organize:
        description: "Skip scanning and go directly to organize results (if scan results exist)"
        required: false
        default: false
        type: boolean

permissions:
  contents: write # Required for creating files and PRs
  packages: read # Required to access GitHub Container Registry
  pull-requests: write # Required to create pull requests
  actions: read # Required for workflow access

jobs:
  check-recent-scans:
    name: Check Recent Scan Results
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Check for recent successful scans
        id: check-recent
        run: |
          echo "Checking for recent successful scan results..."

          # Get recent workflow runs for this workflow
          WORKFLOW_NAME="Trivy Security Scan"
          ONE_WEEK_AGO=$(date -u -d '1 week ago' +%Y-%m-%dT%H:%M:%SZ)

          echo "Looking for successful runs since: $ONE_WEEK_AGO"

          # Check if user disabled recent scan checking or forced a fresh scan
          if [ "${{ github.event.inputs.disable_recent_check }}" == "true" ]; then
            echo "üîÑ Recent scan checking disabled - will skip recent results check"
            echo "recent-scan-available=false" >> $GITHUB_OUTPUT
            echo "recent-run-id=" >> $GITHUB_OUTPUT
            exit 0
          fi

          if [ "${{ github.event.inputs.force_fresh_scan }}" == "true" ]; then
            echo "üîÑ Force fresh scan requested - will skip recent results check"
            echo "recent-scan-available=false" >> $GITHUB_OUTPUT
            echo "recent-run-id=" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get recent workflow runs using GitHub API (without date filter first)
          echo "Fetching recent workflow runs..."
          RECENT_RUNS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs?status=completed&per_page=20")

          # Debug: Show what we got
          echo "API Response status: $(echo "$RECENT_RUNS" | jq -r '.total_count // "unknown"') total runs"

          # Check if we have any successful runs with our workflow name
          RECENT_SUCCESS_COUNT=$(echo "$RECENT_RUNS" | jq -r --arg workflow_name "$WORKFLOW_NAME" '.workflow_runs[]? | select(.name == $workflow_name and .conclusion == "success") | .id' | wc -l)

          echo "Found $RECENT_SUCCESS_COUNT successful runs with workflow name: $WORKFLOW_NAME"

          # Also check for runs that might have completed scanning but failed at PR creation
          RECENT_PARTIAL_SUCCESS_COUNT=$(echo "$RECENT_RUNS" | jq -r --arg workflow_name "$WORKFLOW_NAME" '.workflow_runs[]? | select(.name == $workflow_name and (.conclusion == "failure" or .conclusion == "success")) | .id' | wc -l)

          echo "Found $RECENT_PARTIAL_SUCCESS_COUNT runs (including partial successes) with workflow name: $WORKFLOW_NAME"

          if [ "$RECENT_SUCCESS_COUNT" -gt 0 ]; then
            # Get the most recent successful run
            LATEST_RUN_ID=$(echo "$RECENT_RUNS" | jq -r --arg workflow_name "$WORKFLOW_NAME" '.workflow_runs[]? | select(.name == $workflow_name and .conclusion == "success") | .id' | head -1)
            LATEST_RUN_DATE=$(echo "$RECENT_RUNS" | jq -r --arg run_id "$LATEST_RUN_ID" '.workflow_runs[]? | select(.id == ($run_id | tonumber)) | .created_at')
            
            # Check if the run is recent enough (within 1 week)
            RUN_TIMESTAMP=$(date -d "$LATEST_RUN_DATE" +%s 2>/dev/null || echo "0")
            WEEK_AGO_TIMESTAMP=$(date -d '1 week ago' +%s)
            
            if [ "$RUN_TIMESTAMP" -gt "$WEEK_AGO_TIMESTAMP" ]; then
              echo "‚úì Found recent successful scan:"
              echo "  ‚Üí Run ID: $LATEST_RUN_ID"
              echo "  ‚Üí Date: $LATEST_RUN_DATE"
              echo "  ‚Üí URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/$LATEST_RUN_ID"
              
              echo "recent-scan-available=true" >> $GITHUB_OUTPUT
              echo "recent-run-id=$LATEST_RUN_ID" >> $GITHUB_OUTPUT
            else
              echo "‚ö† Most recent successful scan is too old (older than 1 week)"
              echo "  ‚Üí Run date: $LATEST_RUN_DATE"
              echo "  ‚Üí Will proceed with fresh scan"
              echo "recent-scan-available=false" >> $GITHUB_OUTPUT
              echo "recent-run-id=" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö† No recent successful scans found"
            
            # Check for recent runs that might have scan results even if they failed overall
            echo "üîç Checking for recent runs with potential scan results..."
            RECENT_FAILED_WITH_SCANS=$(echo "$RECENT_RUNS" | jq -r --arg workflow_name "$WORKFLOW_NAME" '.workflow_runs[]? | select(.name == $workflow_name and .conclusion == "failure") | .id' | head -1)
            
            if [ -n "$RECENT_FAILED_WITH_SCANS" ]; then
              FAILED_RUN_DATE=$(echo "$RECENT_RUNS" | jq -r --arg run_id "$RECENT_FAILED_WITH_SCANS" '.workflow_runs[]? | select(.id == ($run_id | tonumber)) | .created_at')
              FAILED_RUN_TIMESTAMP=$(date -d "$FAILED_RUN_DATE" +%s 2>/dev/null || echo "0")
              WEEK_AGO_TIMESTAMP=$(date -d '1 week ago' +%s)
              
              if [ "$FAILED_RUN_TIMESTAMP" -gt "$WEEK_AGO_TIMESTAMP" ]; then
                echo "  ‚Üí Found recent failed run that might have scan results:"
                echo "    ‚Üí Run ID: $RECENT_FAILED_WITH_SCANS"
                echo "    ‚Üí Date: $FAILED_RUN_DATE"
                echo "    ‚Üí Will attempt to reuse scan results from this run"
                
                echo "recent-scan-available=true" >> $GITHUB_OUTPUT
                echo "recent-run-id=$RECENT_FAILED_WITH_SCANS" >> $GITHUB_OUTPUT
              else
                echo "  ‚Üí Recent failed run is too old"
                echo "  ‚Üí Will proceed with fresh scan"
                
                # Debug: Show available workflows
                echo "Available recent workflows:"
                echo "$RECENT_RUNS" | jq -r '.workflow_runs[]? | "  - \(.name) (\(.conclusion)) - \(.created_at)"' | head -5
                
                echo "recent-scan-available=false" >> $GITHUB_OUTPUT
                echo "recent-run-id=" >> $GITHUB_OUTPUT
              fi
            else
              echo "  ‚Üí No recent runs found at all"
              echo "  ‚Üí Will proceed with fresh scan"
              
              # Debug: Show available workflows
              echo "Available recent workflows:"
              echo "$RECENT_RUNS" | jq -r '.workflow_runs[]? | "  - \(.name) (\(.conclusion)) - \(.created_at)"' | head -5
              
              echo "recent-scan-available=false" >> $GITHUB_OUTPUT
              echo "recent-run-id=" >> $GITHUB_OUTPUT
            fi
          fi

    outputs:
      recent-scan-available: ${{ steps.check-recent.outputs.recent-scan-available }}
      recent-run-id: ${{ steps.check-recent.outputs.recent-run-id }}

  security-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: check-recent-scans
    if: always() # Run even if check-recent-scans is skipped

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Discover container images
        id: discover-images
        run: |
          echo "Discovering container images to scan..."

          # Create output file for discovered images
          IMAGES_FILE="images_to_scan.txt"
          > "$IMAGES_FILE"

          # Get organization name from repository
          ORG_NAME="${GITHUB_REPOSITORY_OWNER}"
          echo "Scanning packages for organization: $ORG_NAME"

          # Debug information
          echo ""
          echo "üîç Environment Debug Information:"
          echo "================================="
          echo "  ‚Üí Repository: ${GITHUB_REPOSITORY}"
          echo "  ‚Üí Owner: ${GITHUB_REPOSITORY_OWNER}"
          echo "  ‚Üí Actor: ${GITHUB_ACTOR}"
          echo "  ‚Üí Token available: $([ -n "${{ secrets.GITHUB_TOKEN }}" ] && echo "Yes" || echo "No")"
          echo "  ‚Üí Workflow permissions: packages:read, contents:write, pull-requests:write"
          echo ""

          # Determine which token to use
          if [ -n "${{ secrets.PACKAGES_TOKEN }}" ]; then
            echo "üîë Using PACKAGES_TOKEN (Personal Access Token)"
            AUTH_TOKEN="${{ secrets.PACKAGES_TOKEN }}"
          else
            echo "üîë Using GITHUB_TOKEN (default)"
            AUTH_TOKEN="${{ secrets.GITHUB_TOKEN }}"
          fi

          # Function to make API calls with retry logic
          make_api_call() {
            local url="$1"
            local max_retries=3
            local retry_delay=5
            local attempt=1
            
            while [ $attempt -le $max_retries ]; do
              echo "  ‚Üí API call attempt $attempt/$max_retries: $url" >&2
              
              local response
              local http_code
              
              response=$(curl -s -w "%{http_code}" \
                             --max-time 30 \
                             --retry 0 \
                             -H "Authorization: Bearer $AUTH_TOKEN" \
                             -H "Accept: application/vnd.github.v3+json" \
                             "$url")
              http_code="${response: -3}"
              response="${response%???}"
              
              case "$http_code" in
                200)
                  echo "  ‚úì API call successful (HTTP $http_code)" >&2
                  printf "%s" "$response"
                  return 0
                  ;;
                401|403|404)
                  echo "  ‚úó API call failed (HTTP $http_code)" >&2
                  return 1
                  ;;
                429)
                  echo "  ‚ö† Rate limit exceeded (HTTP $http_code)" >&2
                  if [ $attempt -lt $max_retries ]; then
                    local backoff_delay=$((retry_delay * attempt * 2))
                    echo "    ‚Üí Rate limit backoff: waiting ${backoff_delay}s..." >&2
                    sleep $backoff_delay
                  fi
                  ;;
                5*)
                  echo "  ‚ö† Server error (HTTP $http_code)" >&2
                  if [ $attempt -lt $max_retries ]; then
                    echo "    ‚Üí Retrying in ${retry_delay}s..." >&2
                    sleep $retry_delay
                  fi
                  ;;
              esac
              
              attempt=$((attempt + 1))
            done
            
            echo "  ‚úó API call failed after $max_retries attempts" >&2
            return 1
          }

          # Try organization endpoint first, then user endpoint if that fails
          echo "Fetching container packages from GitHub API..."

          ORG_URL="https://api.github.com/orgs/${ORG_NAME}/packages?package_type=container&per_page=100"
          set +e
          PACKAGES_RESPONSE=$(make_api_call "$ORG_URL")
          ORG_EXIT_CODE=$?
          set -e

          if [ $ORG_EXIT_CODE -eq 0 ] && [ -n "$PACKAGES_RESPONSE" ]; then
            echo "‚úì Organization endpoint successful"
          else
            echo "‚úó Organization endpoint failed, trying user endpoint..."
            USER_URL="https://api.github.com/users/${ORG_NAME}/packages?package_type=container&per_page=100"
            
            set +e
            PACKAGES_RESPONSE=$(make_api_call "$USER_URL")
            USER_EXIT_CODE=$?
            set -e
            
            if [ $USER_EXIT_CODE -eq 0 ] && [ -n "$PACKAGES_RESPONSE" ]; then
              echo "‚úì User endpoint successful"
            else
              echo "‚úó Both endpoints failed"
              exit 1
            fi
          fi

          # Validate and process packages
          if [ -z "$PACKAGES_RESPONSE" ]; then
            echo "‚úó Empty response from GitHub API"
            exit 1
          fi

          TEMP_JSON=$(mktemp)
          printf "%s" "$PACKAGES_RESPONSE" > "$TEMP_JSON"

          if ! jq empty "$TEMP_JSON" 2>/dev/null; then
            echo "‚úó Invalid JSON response from GitHub API"
            rm -f "$TEMP_JSON"
            exit 1
          fi

          # Extract and filter packages for products/bfx/* only
          ALL_PACKAGES_COUNT=$(jq '. | length' "$TEMP_JSON")
          echo "üì¶ Package Discovery Results:"
          echo "============================="
          echo "  ‚Üí Total packages found: $ALL_PACKAGES_COUNT"

          # Get all package names and filter for products/bfx/*
          ALL_PACKAGE_NAMES=$(jq -r '.[].name' "$TEMP_JSON")
          BFX_PACKAGES=$(echo "$ALL_PACKAGE_NAMES" | grep "^products/bfx/" || true)
          BFX_COUNT=$(echo "$BFX_PACKAGES" | grep -c . 2>/dev/null || echo "0")

          echo "  ‚Üí products/bfx/* packages found: $BFX_COUNT"

          if [ "$BFX_COUNT" -eq 0 ]; then
            echo "    ‚ùå No products/bfx/* packages found"
            rm -f "$TEMP_JSON"
            exit 1
          fi

          echo "$BFX_PACKAGES" | sed 's/^/    ‚úì /'
          rm -f "$TEMP_JSON"

          # Process each package to get versions/tags and group by tool
          echo ""
          echo "üöÄ Processing $BFX_COUNT products/bfx/* packages..."
          echo ""

          # Create a mapping file for tool -> images
          TOOL_IMAGES_FILE="tool_images_mapping.json"
          echo "{}" > "$TOOL_IMAGES_FILE"

          echo "$BFX_PACKAGES" | while read -r package_name; do
            if [ -n "$package_name" ]; then
              # Extract tool name from package (products/bfx/toolname -> toolname)
              TOOL_NAME=$(echo "$package_name" | sed 's|products/bfx/||')
              echo "Processing tool: $TOOL_NAME"
              
              # URL encode the package name
              encoded_package_name=$(echo "$package_name" | sed 's|/|%2F|g')
              
              # Get versions for this package
              VERSIONS_URL="https://api.github.com/orgs/${ORG_NAME}/packages/container/${encoded_package_name}/versions?per_page=100"
              VERSIONS_RESPONSE=$(make_api_call "$VERSIONS_URL")
              
              if [ $? -ne 0 ] || [ -z "$VERSIONS_RESPONSE" ]; then
                VERSIONS_URL="https://api.github.com/users/${ORG_NAME}/packages/container/${encoded_package_name}/versions?per_page=100"
                VERSIONS_RESPONSE=$(make_api_call "$VERSIONS_URL")
              fi
              
              if [ $? -eq 0 ] && [ -n "$VERSIONS_RESPONSE" ]; then
                # Validate versions response and extract tags
                if echo "$VERSIONS_RESPONSE" | jq empty 2>/dev/null && echo "$VERSIONS_RESPONSE" | jq -e 'type == "array"' >/dev/null 2>&1; then
                  VERSION_COUNT=$(echo "$VERSIONS_RESPONSE" | jq '. | length')
                  echo "  ‚Üí Found $VERSION_COUNT versions for $TOOL_NAME"
                  
                  # Extract tags and create image URLs, add to tool mapping
                  echo "$VERSIONS_RESPONSE" | jq -r '.[].metadata.container.tags[]?' | while read -r tag; do
                    if [ -n "$tag" ] && [[ ! "$tag" == *.sig ]] && [[ ! "$tag" == sha256-* ]] && [[ "$tag" =~ ^[a-zA-Z0-9._:-]+$ ]]; then
                      image_url="ghcr.io/${ORG_NAME}/${package_name}:${tag}"
                      echo "$image_url" >> "$IMAGES_FILE"
                      
                      # Add to tool mapping
                      jq --arg tool "$TOOL_NAME" --arg image "$image_url" --arg tag "$tag" \
                        '.[$tool] = (.[$tool] // []) + [{"image": $image, "tag": $tag}]' \
                        "$TOOL_IMAGES_FILE" > "${TOOL_IMAGES_FILE}.tmp" && mv "${TOOL_IMAGES_FILE}.tmp" "$TOOL_IMAGES_FILE"
                      
                      echo "    ‚úì Added: $image_url"
                    fi
                  done
                fi
              else
                echo "  ‚úó Failed to fetch versions for $TOOL_NAME"
              fi
            fi
          done

          # Display summary
          if [ -f "$IMAGES_FILE" ] && [ -s "$IMAGES_FILE" ]; then
            IMAGE_COUNT=$(wc -l < "$IMAGES_FILE")
            echo ""
            echo "‚úì Discovery complete. Found $IMAGE_COUNT images to scan"
            
            echo "images-file=$IMAGES_FILE" >> $GITHUB_OUTPUT
            echo "image-count=$IMAGE_COUNT" >> $GITHUB_OUTPUT
            echo "tool-mapping-file=$TOOL_IMAGES_FILE" >> $GITHUB_OUTPUT
          else
            echo ""
            echo "‚ö† No images found to scan"
            echo "images-file=" >> $GITHUB_OUTPUT
            echo "image-count=0" >> $GITHUB_OUTPUT
            echo "tool-mapping-file=" >> $GITHUB_OUTPUT
          fi

      - name: Upload discovered images and mapping
        if: steps.discover-images.outputs.image-count > 0
        uses: actions/upload-artifact@v4
        with:
          name: discovered-images
          path: |
            ${{ steps.discover-images.outputs.images-file }}
            ${{ steps.discover-images.outputs.tool-mapping-file }}
          retention-days: 7

    outputs:
      image-count: ${{ steps.discover-images.outputs.image-count }}
      images-file: ${{ steps.discover-images.outputs.images-file }}
      tool-mapping-file: ${{ steps.discover-images.outputs.tool-mapping-file }}

  trivy-scan:
    name: Trivy Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 180
    needs: [check-recent-scans, security-scan]
    if: needs.security-scan.outputs.image-count > 0

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Setup Trivy database cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/trivy
          key: trivy-db-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            trivy-db-${{ runner.os }}-
            trivy-db-

      - name: Download discovered images and mapping
        uses: actions/download-artifact@v5
        with:
          name: discovered-images

      - name: Debug initial progress files
        run: |
          echo "Checking for any existing progress files..."
          ls -la scan_progress.txt completed_scans.txt failed_scans.txt 2>/dev/null || echo "No progress files found initially"

      - name: Check for recent scan results to reuse
        id: check-reuse
        if: needs.check-recent-scans.outputs.recent-scan-available == 'true' && github.event.inputs.force_fresh_scan != 'true'
        run: |
          echo "Attempting to download recent scan results..."

          RECENT_RUN_ID="${{ needs.check-recent-scans.outputs.recent-run-id }}"
          echo "Checking artifacts from run: $RECENT_RUN_ID"

          # Debug: List available artifacts for this run
          if command -v gh >/dev/null 2>&1; then
            echo "üîç Available artifacts for run $RECENT_RUN_ID:"
            gh api repos/${{ github.repository }}/actions/runs/$RECENT_RUN_ID/artifacts --jq '.artifacts[] | "  - \(.name) (expires: \(.expires_at))"' 2>/dev/null || echo "  ‚Üí Could not list artifacts"
          fi

          mkdir -p recent-results

          if command -v gh >/dev/null 2>&1; then
            echo "Using GitHub CLI to download artifacts..."
            
            DOWNLOADED_ARTIFACTS=0
            
            # Try to download trivy-scan-results first (from successful runs)
            if gh run download "$RECENT_RUN_ID" --name "trivy-scan-results" --dir recent-results/trivy-scan-results 2>/dev/null; then
              echo "‚úì Successfully downloaded trivy-scan-results artifact"
              DOWNLOADED_ARTIFACTS=$((DOWNLOADED_ARTIFACTS + 1))
            else
              echo "‚ö† Failed to download trivy-scan-results"
            fi
            
            # Try to download partial results from failed runs
            if gh run download "$RECENT_RUN_ID" --name "trivy-scan-results-partial" --dir recent-results/trivy-scan-results-partial 2>/dev/null; then
              echo "‚úì Successfully downloaded trivy-scan-results-partial artifact"
              DOWNLOADED_ARTIFACTS=$((DOWNLOADED_ARTIFACTS + 1))
            else
              echo "‚ö† Failed to download trivy-scan-results-partial"
            fi
            
            # Try to download organized-results as additional source
            if gh run download "$RECENT_RUN_ID" --name "organized-results" --dir recent-results/organized-results 2>/dev/null; then
              echo "‚úì Successfully downloaded organized-results artifact"
              DOWNLOADED_ARTIFACTS=$((DOWNLOADED_ARTIFACTS + 1))
            else
              echo "‚ö† Failed to download organized-results"
            fi
            
            # Try to download final scan results as ultimate fallback
            if gh run download "$RECENT_RUN_ID" --name "trivy-scan-results-final" --dir recent-results/trivy-scan-results-final 2>/dev/null; then
              echo "‚úì Successfully downloaded trivy-scan-results-final artifact"
              DOWNLOADED_ARTIFACTS=$((DOWNLOADED_ARTIFACTS + 1))
            else
              echo "‚ö† Failed to download trivy-scan-results-final"
            fi
            
            if [ $DOWNLOADED_ARTIFACTS -gt 0 ]; then
              echo "reuse-available=true" >> $GITHUB_OUTPUT
              
              # Count total JSON files from all downloaded artifacts
              JSON_COUNT=0
              if [ -d "recent-results" ]; then
                JSON_COUNT=$(find recent-results -name "*.json" -type f | wc -l)
              fi
              
              echo "  ‚Üí Downloaded $DOWNLOADED_ARTIFACTS artifact(s)"
              echo "  ‚Üí Found $JSON_COUNT JSON files total"
              echo "json-count=$JSON_COUNT" >> $GITHUB_OUTPUT
            else
              echo "‚ö† Failed to download any scan results from run $RECENT_RUN_ID"
              echo "  ‚Üí This might be expected if the run failed before creating artifacts"
              echo "reuse-available=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö† GitHub CLI not available, cannot download recent artifacts"
            echo "reuse-available=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Pre-warm Trivy database cache
        if: steps.check-reuse.outputs.reuse-available != 'true' || github.event.inputs.force_fresh_scan == 'true'
        run: |
          echo "Pre-warming Trivy database cache..."
          mkdir -p ~/.cache/trivy

          docker run --rm \
            -v "$HOME/.cache/trivy:/root/.cache/trivy" \
            -e TRIVY_CACHE_DIR="/root/.cache/trivy" \
            aquasec/trivy:latest image --download-db-only

          echo "‚úì Trivy database cache pre-warmed"

      - name: Check for existing scan progress
        id: check-progress
        if: steps.check-reuse.outputs.reuse-available != 'true' || github.event.inputs.force_fresh_scan == 'true'
        run: |
          echo "Checking for existing scan progress..."

          IMAGES_FILE="images_to_scan.txt"
          PROGRESS_FILE="scan_progress.txt"
          COMPLETED_FILE="completed_scans.txt"

          # Create progress tracking files
          touch "$PROGRESS_FILE"
          touch "$COMPLETED_FILE"

          # Check if user wants to resume from progress
          if [ "${{ github.event.inputs.resume_from_progress }}" != "true" ]; then
            echo "üîÑ Resume from progress disabled - starting fresh scan"
            > "$COMPLETED_FILE"  # Clear completed file
            > "$PROGRESS_FILE"   # Clear progress file
          fi

          # Also check if there are existing scan results in the current workspace
          if [ ! -s "$COMPLETED_FILE" ] && [ -d "trivy-results" ]; then
            echo "üîç Checking for existing scan results in current workspace..."
            EXISTING_RESULTS=$(find trivy-results -name "trivy-*.json" -type f | wc -l)
            if [ "$EXISTING_RESULTS" -gt 0 ]; then
              echo "  ‚Üí Found $EXISTING_RESULTS existing scan result files"
              echo "  ‚Üí Extracting image URLs from existing results..."
              
              # Extract image URLs from existing JSON files and add to completed list
              for json_file in trivy-results/trivy-*.json; do
                if [ -f "$json_file" ]; then
                  # Try to extract image URL from metadata or filename
                  IMAGE_URL=$(jq -r '.Metadata.ImageID // empty' "$json_file" 2>/dev/null || true)
                  if [ -z "$IMAGE_URL" ]; then
                    # Fallback: reconstruct from filename
                    SAFE_NAME=$(basename "$json_file" .json | sed 's/^trivy-//')
                    # This is a rough reconstruction - may not be perfect
                    echo "  ‚ö† Could not extract image URL from $json_file"
                  else
                    echo "$IMAGE_URL" >> "$COMPLETED_FILE"
                    echo "  ‚úì Added existing result: $IMAGE_URL"
                  fi
                fi
              done
              
              if [ -s "$COMPLETED_FILE" ]; then
                RECOVERED_COUNT=$(wc -l < "$COMPLETED_FILE")
                echo "  ‚Üí Recovered $RECOVERED_COUNT completed scans from existing results"
              fi
            fi
          fi

          TOTAL_IMAGES=$(wc -l < "$IMAGES_FILE")
          COMPLETED_COUNT=0

          if [ -s "$COMPLETED_FILE" ]; then
            COMPLETED_COUNT=$(wc -l < "$COMPLETED_FILE")
            echo "üìã Found existing scan progress:"
            echo "  ‚Üí Total images: $TOTAL_IMAGES"
            echo "  ‚Üí Already completed: $COMPLETED_COUNT"
            echo "  ‚Üí Remaining: $((TOTAL_IMAGES - COMPLETED_COUNT))"
            
            # Create list of remaining images to scan
            REMAINING_FILE="remaining_to_scan.txt"
            comm -23 <(sort "$IMAGES_FILE") <(sort "$COMPLETED_FILE") > "$REMAINING_FILE"
            
            echo "resume-scan=true" >> $GITHUB_OUTPUT
            echo "remaining-file=$REMAINING_FILE" >> $GITHUB_OUTPUT
            echo "completed-count=$COMPLETED_COUNT" >> $GITHUB_OUTPUT
          else
            echo "üìã No existing progress found - starting fresh scan"
            echo "  ‚Üí Total images to scan: $TOTAL_IMAGES"
            
            echo "resume-scan=false" >> $GITHUB_OUTPUT
            echo "remaining-file=$IMAGES_FILE" >> $GITHUB_OUTPUT
            echo "completed-count=0" >> $GITHUB_OUTPUT
          fi

      - name: Batch scan images with Trivy
        id: batch-scan
        timeout-minutes: 150
        if: (steps.check-reuse.outputs.reuse-available != 'true' || github.event.inputs.force_fresh_scan == 'true') && github.event.inputs.skip_to_organize != 'true'
        run: |
          IMAGES_FILE="${{ steps.check-progress.outputs.remaining-file }}"
          PROGRESS_FILE="scan_progress.txt"
          COMPLETED_FILE="completed_scans.txt"
          FAILED_FILE="failed_scans.txt"

          SCAN_COUNT=0
          SUCCESS_COUNT=${{ steps.check-progress.outputs.completed-count }}
          FAILURE_COUNT=0
          TOTAL_IMAGES=$(wc -l < "images_to_scan.txt")
          REMAINING_IMAGES=$(wc -l < "$IMAGES_FILE")

          if [ "${{ steps.check-progress.outputs.resume-scan }}" == "true" ]; then
            echo "üîÑ Resuming batch scan from previous progress..."
            echo "  ‚Üí Already completed: $SUCCESS_COUNT images"
            echo "  ‚Üí Remaining to scan: $REMAINING_IMAGES images"
          else
            echo "üöÄ Starting fresh batch scan of $TOTAL_IMAGES images using Trivy..."
          fi

          # Log why we're doing a fresh scan
          if [ "${{ github.event.inputs.force_fresh_scan }}" == "true" ]; then
            echo "üîÑ Performing fresh scan (forced by user input)"
          elif [ "${{ needs.check-recent-scans.outputs.recent-scan-available }}" == "true" ]; then
            echo "üîÑ Performing fresh scan (recent results not usable)"
          else
            echo "üîÑ Performing fresh scan (no recent results available)"
          fi
          echo ""

          # Set up results directory
          mkdir -p trivy-results

          # Process each image with progress tracking
          QUEUE_POSITION=0
          while IFS= read -r image_url; do
            if [ -n "$image_url" ]; then
              QUEUE_POSITION=$((QUEUE_POSITION + 1))
              echo "[$QUEUE_POSITION/$REMAINING_IMAGES] Processing: $image_url"
              
              # Check if this image was already scanned successfully
              if grep -Fxq "$image_url" "$COMPLETED_FILE" 2>/dev/null; then
                echo "  ‚è≠ Already scanned - skipping"
                continue
              fi
              
              # Also check if scan result already exists from recent download
              SAFE_NAME=$(echo "$image_url" | sed 's|[^a-zA-Z0-9._-]|_|g')
              JSON_FILE="trivy-results/trivy-${SAFE_NAME}.json"
              if [ -f "$JSON_FILE" ]; then
                echo "  ‚è≠ Scan result already exists from recent download - skipping"
                echo "$image_url" >> "$COMPLETED_FILE"
                SCAN_COUNT=$((SCAN_COUNT + 1))
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                continue
              fi
              
              # Create safe filename for outputs
              SAFE_NAME=$(echo "$image_url" | sed 's|[^a-zA-Z0-9._-]|_|g')
              JSON_FILE="trivy-results/trivy-${SAFE_NAME}.json"
              
              # Record scan attempt
              echo "$(date -u +%Y-%m-%dT%H:%M:%SZ) SCANNING $image_url" >> "$PROGRESS_FILE"
              
              # Attempt Trivy scan with JSON output
              if timeout 15m docker run --rm \
                --memory=2g \
                --cpus=2 \
                -v "$(pwd)/trivy-results:/output" \
                -v "$HOME/.cache/trivy:/root/.cache/trivy" \
                -e TRIVY_USERNAME="${{ github.actor }}" \
                -e TRIVY_PASSWORD="${{ secrets.GITHUB_TOKEN }}" \
                -e TRIVY_CACHE_DIR="/root/.cache/trivy" \
                aquasec/trivy:latest image \
                --format json \
                --severity CRITICAL,HIGH \
                --timeout 12m \
                --exit-code 0 \
                --skip-update \
                --output "/output/trivy-${SAFE_NAME}.json" \
                "$image_url" 2>/dev/null; then
                
                SCAN_COUNT=$((SCAN_COUNT + 1))
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                echo "  ‚úì Scan completed successfully"
                
                # Record successful completion
                echo "$image_url" >> "$COMPLETED_FILE"
                echo "$(date -u +%Y-%m-%dT%H:%M:%SZ) SUCCESS $image_url" >> "$PROGRESS_FILE"
                
                if [ -f "$JSON_FILE" ]; then
                  VULN_COUNT=$(jq -r '.Results[]?.Vulnerabilities // [] | length' "$JSON_FILE" 2>/dev/null | awk '{sum+=$1} END {print sum+0}')
                  echo "  ‚Üí Found $VULN_COUNT vulnerabilities (CRITICAL/HIGH)"
                fi
                
                # Save progress every 5 successful scans
                if [ $((SCAN_COUNT % 5)) -eq 0 ]; then
                  echo "  üíæ Progress checkpoint: $SCAN_COUNT scans completed in this run"
                fi
              else
                SCAN_COUNT=$((SCAN_COUNT + 1))
                FAILURE_COUNT=$((FAILURE_COUNT + 1))
                echo "  ‚úó Scan failed - continuing with next image"
                
                # Record failure
                echo "$image_url" >> "$FAILED_FILE"
                echo "$(date -u +%Y-%m-%dT%H:%M:%SZ) FAILED $image_url" >> "$PROGRESS_FILE"
              fi
              
              echo ""
            fi
          done < "$IMAGES_FILE"

          echo ""
          echo "Batch Scan Summary"
          echo "=================="
          echo "Total images discovered: $TOTAL_IMAGES"
          echo "Images in current queue: $REMAINING_IMAGES"
          echo "Images processed this run: $SCAN_COUNT"
          echo "Successful scans this run: $((SCAN_COUNT - FAILURE_COUNT))"
          echo "Failed scans this run: $FAILURE_COUNT"
          echo "Total successful scans overall: $SUCCESS_COUNT"

          # Calculate completion percentage
          if [ $TOTAL_IMAGES -gt 0 ]; then
            COMPLETION_PCT=$(( SUCCESS_COUNT * 100 / TOTAL_IMAGES ))
            echo "Overall completion: $SUCCESS_COUNT/$TOTAL_IMAGES ($COMPLETION_PCT%)"
          fi

          # Show progress file info
          if [ -f "$PROGRESS_FILE" ]; then
            echo "Progress log entries: $(wc -l < "$PROGRESS_FILE")"
          fi

          if [ -f "$FAILED_FILE" ]; then
            FAILED_TOTAL=$(wc -l < "$FAILED_FILE")
            if [ $FAILED_TOTAL -gt 0 ]; then
              echo "Total failed images: $FAILED_TOTAL"
              echo "Failed images can be retried in next run"
            fi
          fi

          echo "total-scanned=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "successful-scans=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "failed-scans=$FAILURE_COUNT" >> $GITHUB_OUTPUT

          if [ $SUCCESS_COUNT -gt 0 ]; then
            echo "‚úì Batch scan completed with $SUCCESS_COUNT successful scans"
            if [ $SCAN_COUNT -lt $REMAINING_IMAGES ]; then
              echo "‚ö† Note: Scan was interrupted. Run workflow again to resume from progress."
            fi
            exit 0
          else
            echo "‚úó No successful scans in this run"
            if [ $SUCCESS_COUNT -gt 0 ]; then
              echo "  ‚Üí But $SUCCESS_COUNT images were completed in previous runs"
              exit 0
            else
              exit 1
            fi
          fi

      - name: Upload individual scan results as artifacts
        if: steps.batch-scan.outputs.successful-scans > 0
        uses: actions/upload-artifact@v4
        with:
          name: trivy-scan-results
          path: |
            trivy-results/
            scan_progress.txt
            completed_scans.txt
            failed_scans.txt
          retention-days: 30
          compression-level: 6
        continue-on-error: true

      - name: Upload partial scan results (even if batch failed)
        if: always() && (steps.batch-scan.conclusion == 'failure' || steps.batch-scan.conclusion == 'cancelled')
        uses: actions/upload-artifact@v4
        with:
          name: trivy-scan-results-partial
          path: |
            trivy-results/
            scan_progress.txt
            completed_scans.txt
            failed_scans.txt
          retention-days: 30
          compression-level: 6
        continue-on-error: true

      - name: Upload scan progress immediately
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scan-progress
          path: |
            scan_progress.txt
            completed_scans.txt
            failed_scans.txt
          retention-days: 30

      - name: Prepare results from recent scans or skip to organize
        if: (steps.check-reuse.outputs.reuse-available == 'true' && steps.check-reuse.outputs.json-count > 0) || github.event.inputs.skip_to_organize == 'true'
        id: prepare-recent
        run: |
          if [ "${{ github.event.inputs.skip_to_organize }}" == "true" ]; then
            echo "‚è≠ Skipping to organize existing results..."
            echo "Using existing trivy-results directory"
          else
            echo "Preparing recent scan results for processing..."
            # Copy recent results to current results directory
            mkdir -p trivy-results
            
            if [ -d "recent-results" ]; then
              echo "üì• Processing downloaded artifacts..."
              
              # Process each downloaded artifact directory
              for artifact_dir in recent-results/*/; do
                if [ -d "$artifact_dir" ]; then
                  ARTIFACT_NAME=$(basename "$artifact_dir")
                  echo "  ‚Üí Processing artifact: $ARTIFACT_NAME"
                  
                  # Copy trivy-results directory if it exists
                  if [ -d "$artifact_dir/trivy-results" ]; then
                    echo "    ‚Üí Copying trivy-results from $ARTIFACT_NAME..."
                    cp -r "$artifact_dir/trivy-results"/* trivy-results/ 2>/dev/null || true
                  fi
                  
                  # Copy individual JSON files if they exist at root level
                  if find "$artifact_dir" -maxdepth 1 -name "*.json" -type f | head -1 >/dev/null; then
                    echo "    ‚Üí Copying JSON files from $ARTIFACT_NAME..."
                    cp "$artifact_dir"/*.json trivy-results/ 2>/dev/null || true
                  fi
                  
                  # Copy progress files if they exist
                  for progress_file in scan_progress.txt completed_scans.txt failed_scans.txt; do
                    if [ -f "$artifact_dir/$progress_file" ]; then
                      echo "    ‚Üí Copying progress file: $progress_file from $ARTIFACT_NAME"
                      cp "$artifact_dir/$progress_file" . 2>/dev/null || true
                    fi
                  done
                fi
              done
              
              # Also check for files at the root level of recent-results
              if find recent-results -maxdepth 1 -name "*.json" -type f | head -1 >/dev/null; then
                echo "  ‚Üí Copying root-level JSON files..."
                cp recent-results/*.json trivy-results/ 2>/dev/null || true
              fi
              
              # Copy root-level progress files
              for progress_file in scan_progress.txt completed_scans.txt failed_scans.txt; do
                if [ -f "recent-results/$progress_file" ]; then
                  echo "  ‚Üí Copying root-level progress file: $progress_file"
                  cp "recent-results/$progress_file" . 2>/dev/null || true
                fi
              done
              
              echo "  ‚úì Recent results prepared for reuse"
            else
              echo "  ‚ö† No recent-results directory found"
            fi
          fi

          # Count available JSON files
          JSON_COUNT=0
          for json_file in trivy-results/*.json; do
            if [ -f "$json_file" ]; then
              JSON_COUNT=$((JSON_COUNT + 1))
            fi
          done

          echo "‚úì Prepared $JSON_COUNT JSON files from recent scan"

          # Show what was reused for debugging
          if [ $JSON_COUNT -gt 0 ]; then
            echo "üìä Reused scan results summary:"
            echo "  ‚Üí Total JSON files: $JSON_COUNT"
            echo "  ‚Üí Sample files:"
            ls trivy-results/*.json | head -5 | sed 's/^/    - /'
            if [ $JSON_COUNT -gt 5 ]; then
              echo "    - ... and $((JSON_COUNT - 5)) more files"
            fi
          fi

          # Check for progress files
          if [ -f "completed_scans.txt" ]; then
            COMPLETED_COUNT=$(wc -l < completed_scans.txt)
            echo "  ‚Üí Completed scans list: $COMPLETED_COUNT entries"
          fi

          echo "‚ö° Time saved by reusing recent results: ~120-180 minutes"
          echo "üí∞ Resources saved: Significant CPU, memory, and network usage"

          # Set outputs to match batch-scan outputs for consistency
          echo "successful-scans=$JSON_COUNT" >> $GITHUB_OUTPUT
          echo "total-scanned=$JSON_COUNT" >> $GITHUB_OUTPUT
          echo "failed-scans=0" >> $GITHUB_OUTPUT

      - name: Organize scan results by tool
        if: (steps.batch-scan.outputs.successful-scans > 0) || (steps.prepare-recent.outputs.successful-scans > 0)
        id: organize-results
        run: |
          echo "Organizing scan results by tool..."

          TOOL_MAPPING_FILE="tool_images_mapping.json"
          ORGANIZED_DIR="organized-results"
          mkdir -p "$ORGANIZED_DIR"

          if [ ! -f "$TOOL_MAPPING_FILE" ]; then
            echo "‚úó Tool mapping file not found"
            exit 1
          fi

          # Validate tool mapping file
          if ! jq empty "$TOOL_MAPPING_FILE" 2>/dev/null; then
            echo "‚úó Tool mapping file contains invalid JSON"
            exit 1
          fi

          # Get list of tools
          TOOLS=$(jq -r 'keys[]' "$TOOL_MAPPING_FILE" 2>/dev/null)
          if [ -z "$TOOLS" ]; then
            echo "‚úó No tools found in mapping file"
            exit 1
          fi

          TOOL_COUNT=0
          echo "Processing tools and organizing scan results..."
          echo "Tools to process: $(echo "$TOOLS" | tr '\n' ' ')"

          for tool in $TOOLS; do
            TOOL_COUNT=$((TOOL_COUNT + 1))
            echo "[$TOOL_COUNT] Processing tool: $tool"
            
            # Create tool-specific result file
            TOOL_RESULT_FILE="$ORGANIZED_DIR/${tool}-trivy-scan-results.json"
            
            # Initialize tool result structure
            echo "{\"tool\": \"$tool\", \"scan_timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"workflow_run_id\": \"${{ github.run_id }}\", \"versions\": {}, \"summary\": {\"total_versions_scanned\": 0, \"total_vulnerabilities\": 0}}" > "$TOOL_RESULT_FILE"

            # Process each image for this tool
            jq -r --arg tool "$tool" '.[$tool][]? | .image' "$TOOL_MAPPING_FILE" | while read -r image_url; do
              if [ -n "$image_url" ]; then
                # Find corresponding scan result file
                SAFE_NAME=$(echo "$image_url" | sed 's|[^a-zA-Z0-9._-]|_|g')
                SCAN_FILE="trivy-results/trivy-${SAFE_NAME}.json"
                
                if [ -f "$SCAN_FILE" ]; then
                  # Extract tag/version from image URL
                  TAG=$(echo "$image_url" | sed 's|.*:||')
                  echo "  ‚Üí Adding results for version: $TAG"
                  
                  # Count vulnerabilities directly from file (avoid loading large data into memory)
                  VULN_COUNT=$(jq -r '[.Results[]?.Vulnerabilities[]?] | length' "$SCAN_FILE" 2>/dev/null || echo "0")
                  
                  # Create a temporary file with just the vulnerability data
                  TEMP_VULNS=$(mktemp)
                  jq -r '.Results[]?.Vulnerabilities // []' "$SCAN_FILE" > "$TEMP_VULNS" 2>/dev/null || echo "[]" > "$TEMP_VULNS"
                  
                  # Add version data to tool result file using file input instead of command line args
                  jq --arg tag "$TAG" \
                     --arg image "$image_url" \
                     --argjson count "$VULN_COUNT" \
                     --slurpfile vulns "$TEMP_VULNS" \
                     '.versions[$tag] = {
                       "image": $image,
                       "vulnerabilities": $vulns[0],
                       "vulnerability_count": $count
                     }' "$TOOL_RESULT_FILE" > "${TOOL_RESULT_FILE}.tmp" && mv "${TOOL_RESULT_FILE}.tmp" "$TOOL_RESULT_FILE"
                  
                  # Clean up temp file
                  rm -f "$TEMP_VULNS"
                  
                  echo "    ‚úì Added $VULN_COUNT vulnerabilities"
                else
                  echo "  ‚ö† Scan result not found for: $image_url"
                fi
              fi
            done

            # Update summary by counting from the actual data in the file
            VERSION_COUNT=$(jq -r '.versions | keys | length' "$TOOL_RESULT_FILE")
            TOTAL_VULNS=$(jq -r '[.versions[].vulnerability_count] | add // 0' "$TOOL_RESULT_FILE")
            
            jq --argjson version_count "$VERSION_COUNT" \
               --argjson total_vulns "$TOTAL_VULNS" \
               '.summary.total_versions_scanned = $version_count |
                .summary.total_vulnerabilities = $total_vulns' \
               "$TOOL_RESULT_FILE" > "${TOOL_RESULT_FILE}.tmp" && mv "${TOOL_RESULT_FILE}.tmp" "$TOOL_RESULT_FILE"

            echo "  ‚úì Organized $VERSION_COUNT versions with $TOTAL_VULNS total vulnerabilities"
          done

          echo ""
          echo "‚úì Organization complete. Processed $TOOL_COUNT tools"
          echo "organized-dir=$ORGANIZED_DIR" >> $GITHUB_OUTPUT
          echo "tool-count=$TOOL_COUNT" >> $GITHUB_OUTPUT

      - name: Upload organized scan results as artifacts
        if: steps.organize-results.outputs.tool-count > 0
        uses: actions/upload-artifact@v4
        with:
          name: organized-results
          path: |
            ${{ steps.organize-results.outputs.organized-dir }}/
          retention-days: 90
          compression-level: 6
        continue-on-error: true

      - name: Upload final scan results (safety backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-scan-results-final
          path: |
            trivy-results/
            organized-results/
            scan_progress.txt
            completed_scans.txt
            failed_scans.txt
            tool_images_mapping.json
          retention-days: 90
          compression-level: 6
        continue-on-error: true

      - name: Artifact Summary
        if: always()
        run: |
          echo "üì¶ Artifacts Created Summary"
          echo "=========================="

          # Count scan results
          if [ -d "trivy-results" ]; then
            SCAN_COUNT=$(find trivy-results -name "*.json" -type f | wc -l)
            echo "‚úÖ Raw scan results: $SCAN_COUNT JSON files"
          fi

          # Count organized results
          if [ -d "organized-results" ]; then
            ORG_COUNT=$(find organized-results -name "*.json" -type f | wc -l)
            echo "‚úÖ Organized results: $ORG_COUNT tool files"
          fi

          # Show progress files
          for file in scan_progress.txt completed_scans.txt failed_scans.txt; do
            if [ -f "$file" ]; then
              LINES=$(wc -l < "$file")
              echo "‚úÖ Progress file: $file ($LINES entries)"
            fi
          done

          echo ""
          echo "üéØ These artifacts will be available for reuse in future runs"
          echo "üíæ Retention: 30 days (scan results), 90 days (organized results)"

      - name: Analyze changes for intelligent PR creation
        if: steps.organize-results.outputs.tool-count > 0
        id: analyze-changes
        run: |
          echo "Creating Pull Request with organized scan results..."

          ORGANIZED_DIR="${{ steps.organize-results.outputs.organized-dir }}"
          TOOL_COUNT="${{ steps.organize-results.outputs.tool-count }}"
          BRANCH_NAME="trivy-security-scan-$(date +%Y-%m-%d)"

          # Debug: Show what we received from organize step
          echo "üîç Debug Information:"
          echo "  ‚Üí ORGANIZED_DIR from output: '$ORGANIZED_DIR'"
          echo "  ‚Üí TOOL_COUNT from output: '$TOOL_COUNT'"
          echo "  ‚Üí Current working directory: $(pwd)"
          echo "  ‚Üí Available directories:"
          ls -la . | grep "^d" || echo "    No directories found"

          # Fallback: If organized-dir output is empty, use default
          if [ -z "$ORGANIZED_DIR" ]; then
            echo "‚ö† ORGANIZED_DIR is empty, using default: organized-results"
            ORGANIZED_DIR="organized-results"
          fi

          # Ensure organized directory exists (recreate if needed)
          if [ ! -d "$ORGANIZED_DIR" ]; then
            echo "‚ö† Organized directory does not exist: $ORGANIZED_DIR"
            echo "üîß Attempting to recreate from available files..."
            
            # Check if we have organized results in current directory
            if find . -maxdepth 1 -name "*-trivy-scan-results.json" -type f | head -1 >/dev/null; then
              echo "  ‚Üí Found organized result files in current directory"
              mkdir -p "$ORGANIZED_DIR"
              mv *-trivy-scan-results.json "$ORGANIZED_DIR/" 2>/dev/null || true
              echo "  ‚Üí Moved files to $ORGANIZED_DIR"
            else
              echo "  ‚Üí No organized result files found in current directory"
              echo "  ‚Üí Available files:"
              ls -la . | head -10
              exit 1
            fi
          fi

          # First, verify and secure the organized directory BEFORE any git operations
          echo "üîí Securing organized directory before git operations..."
          if [ -d "$ORGANIZED_DIR" ]; then
            echo "‚úÖ Organized directory exists before git operations"
            echo "Files in organized directory:"
            ls -la "$ORGANIZED_DIR"
            echo ""
            echo "Files matching pattern *-trivy-scan-results.json:"
            find "$ORGANIZED_DIR" -name "*-trivy-scan-results.json" -type f || echo "No files match pattern"
            echo ""
            echo "All JSON files in directory:"
            find "$ORGANIZED_DIR" -name "*.json" -type f || echo "No JSON files found"
          else
            echo "‚úó Organized directory does not exist before git operations: $ORGANIZED_DIR"
            exit 1
          fi

          # Configure git
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

          # Check git status and clean working directory
          echo "Checking git status before creating branch..."
          git status --porcelain

          # Backup organized directory before git operations to a safe location
          echo "üíæ Backing up organized directory before git operations..."
          BACKUP_DIR="/tmp/organized-results-backup-$$"
          if [ -d "$ORGANIZED_DIR" ]; then
            cp -r "$ORGANIZED_DIR" "$BACKUP_DIR"
            echo "  ‚úì Backed up organized directory to $BACKUP_DIR"
          else
            echo "  ‚úó No organized directory to backup"
            exit 1
          fi

          # Ensure clean working directory
          if [ -n "$(git status --porcelain)" ]; then
            echo "Working directory not clean - stashing changes..."
            git stash push -m "Auto-stash before PR creation" --include-untracked 2>/dev/null || true
          fi

          # Create and switch to new branch from clean main
          echo "üåø Creating branch: $BRANCH_NAME"

          # Check if branch already exists locally
          if git show-ref --verify --quiet refs/heads/"$BRANCH_NAME"; then
            echo "‚ö† Branch $BRANCH_NAME already exists locally"
            echo "üîÑ Switching to existing branch and updating it..."
            git checkout "$BRANCH_NAME"
            
            # Reset to main to ensure clean state
            git reset --hard main
            echo "  ‚úì Reset branch to latest main"
          else
            # Check if branch exists on remote
            if git ls-remote --exit-code --heads origin "$BRANCH_NAME" >/dev/null 2>&1; then
              echo "‚ö† Branch $BRANCH_NAME exists on remote"
              echo "üîÑ Fetching and checking out remote branch..."
              git fetch origin "$BRANCH_NAME"
              git checkout -b "$BRANCH_NAME" origin/"$BRANCH_NAME"
              
              # Reset to main to ensure clean state
              git reset --hard main
              echo "  ‚úì Reset branch to latest main"
            else
              echo "‚úÖ Creating new branch: $BRANCH_NAME"
              git checkout -b "$BRANCH_NAME"
            fi
          fi

          # Restore organized directory from backup
          echo "üîÑ Restoring organized directory from backup..."
          echo "  ‚Üí Looking for backup at: $BACKUP_DIR"

          if [ -d "$BACKUP_DIR" ]; then
            echo "  ‚úì Backup directory found"
            BACKUP_FILE_COUNT=$(find "$BACKUP_DIR" -name "*.json" -type f | wc -l)
            echo "  ‚Üí Backup contains $BACKUP_FILE_COUNT JSON files"
            
            rm -rf "$ORGANIZED_DIR" 2>/dev/null || true
            cp -r "$BACKUP_DIR" "$ORGANIZED_DIR"
            rm -rf "$BACKUP_DIR"  # Clean up backup
            echo "  ‚úì Restored organized directory from backup"
            
            # Verify restoration
            FILE_COUNT=$(find "$ORGANIZED_DIR" -name "*.json" -type f | wc -l)
            echo "  ‚Üí Restored directory contains $FILE_COUNT JSON files"
          else
            echo "  ‚úó Backup directory not found: $BACKUP_DIR"
            echo "  ‚Üí Available files in /tmp:"
            ls -la /tmp/ | grep organized || echo "    No organized backup files found"
            exit 1
          fi

          # Copy organized results to their respective tool directories
          COPIED_FILES=0
          echo "Looking for files matching pattern: $ORGANIZED_DIR/*-trivy-scan-results.json"

          # Use a more robust file finding approach
          if [ -d "$ORGANIZED_DIR" ]; then
            # First, let's use a simple approach that works with the COPIED_FILES counter
            for result_file in "$ORGANIZED_DIR"/*-trivy-scan-results.json; do
              # Check if the glob matched any files
              if [ ! -e "$result_file" ]; then
                echo "No files matching pattern *-trivy-scan-results.json found"
                echo "Trying alternative patterns..."
                
                # Try alternative patterns
                for alt_file in "$ORGANIZED_DIR"/*.json; do
                  if [ -e "$alt_file" ]; then
                    echo "Found alternative file: $alt_file"
                    result_file="$alt_file"
                    break
                  fi
                done
                
                if [ ! -e "$result_file" ]; then
                  echo "No JSON files found at all"
                  break
                fi
              fi
              
              if [ -f "$result_file" ]; then
                echo "Processing file: $result_file"
                
                # Extract tool name from filename (handle different patterns)
                FILENAME=$(basename "$result_file")
                if [[ "$FILENAME" == *"-trivy-scan-results.json" ]]; then
                  TOOL_NAME=$(echo "$FILENAME" | sed 's|-trivy-scan-results.json||')
                else
                  # Fallback: try to extract tool name from JSON content
                  TOOL_NAME=$(jq -r '.tool // empty' "$result_file" 2>/dev/null)
                  if [ -z "$TOOL_NAME" ]; then
                    # Last resort: use filename without extension
                    TOOL_NAME=$(echo "$FILENAME" | sed 's|\.json||')
                  fi
                fi
                
                # Try to find matching directory in bfx/
                TARGET_DIR=""
                
                # First try exact match
                if [ -d "bfx/$TOOL_NAME" ]; then
                  TARGET_DIR="bfx/$TOOL_NAME"
                else
                  # Try fuzzy matching - look for directories that contain the tool name
                  POSSIBLE_DIRS=$(find bfx/ -maxdepth 1 -type d -name "*$TOOL_NAME*" 2>/dev/null || true)
                  if [ -n "$POSSIBLE_DIRS" ]; then
                    TARGET_DIR=$(echo "$POSSIBLE_DIRS" | head -1)
                    echo "  ‚Üí Found fuzzy match: $TARGET_DIR for tool $TOOL_NAME"
                  else
                    # Try reverse - look for tool names that are contained in directory names
                    for bfx_dir in bfx/*/; do
                      if [ -d "$bfx_dir" ]; then
                        DIR_NAME=$(basename "$bfx_dir")
                        if [[ "$TOOL_NAME" == *"$DIR_NAME"* ]] || [[ "$DIR_NAME" == *"$TOOL_NAME"* ]]; then
                          TARGET_DIR="$bfx_dir"
                          echo "  ‚Üí Found reverse match: $TARGET_DIR for tool $TOOL_NAME"
                          break
                        fi
                      fi
                    done
                  fi
                fi
                
                if [ -z "$TARGET_DIR" ]; then
                  echo "  ‚úó No matching directory found for tool: $TOOL_NAME"
                  echo "  ‚Üí Available directories in bfx/:"
                  ls -1 bfx/ | head -10 | sed 's/^/    - /'
                  echo "  ‚Üí Skipping this tool"
                  continue
                fi
                
                TARGET_FILE="$TARGET_DIR/trivy-scan-results.json"
                
                echo "  ‚Üí Tool: $TOOL_NAME"
                echo "  ‚Üí Target directory: $TARGET_DIR"
                echo "  ‚Üí Target file: $TARGET_FILE"
                
                if [ -d "$TARGET_DIR" ]; then
                  echo "  ‚úì Target directory exists"
                  echo "Copying scan results for: $TOOL_NAME"
                  cp "$result_file" "$TARGET_FILE"
                  
                  # Only add the specific scan result file (not workflow files)
                  git add "$TARGET_FILE"
                  COPIED_FILES=$((COPIED_FILES + 1))
                  
                  # Show summary of what was added
                  VERSIONS=$(jq -r '.summary.total_versions_scanned' "$TARGET_FILE")
                  VULNS=$(jq -r '.summary.total_vulnerabilities' "$TARGET_FILE")
                  echo "  ‚Üí $VERSIONS versions scanned, $VULNS vulnerabilities found"
                else
                  echo "  ‚úó Target directory not found: $TARGET_DIR"
                  echo "  ‚Üí Available directories in bfx/:"
                  ls -la bfx/ | head -10
                fi
              fi
            done
          else
            echo "‚úó Organized directory not found: $ORGANIZED_DIR"
            exit 1
          fi

          # Verify what we're about to commit
          echo ""
          echo "Files staged for commit:"
          git diff --cached --name-only

          # Ensure no workflow files are staged
          if git diff --cached --name-only | grep -q "\.github/workflows/"; then
            echo "‚ö† Workflow files detected in staging area - removing them"
            git reset HEAD .github/workflows/ 2>/dev/null || true
          fi

          if [ $COPIED_FILES -eq 0 ]; then
            echo "‚úó No files were copied to target directories"
            exit 1
          fi

          # Final validation - ensure only scan result files are staged
          STAGED_FILES=$(git diff --cached --name-only)
          if [ -z "$STAGED_FILES" ]; then
            echo "‚úó No files staged for commit"
            exit 1
          fi

          echo ""
          echo "Final validation - Files staged for commit:"
          echo "$STAGED_FILES"

          # Check if any non-scan-result files are staged
          NON_SCAN_FILES=$(echo "$STAGED_FILES" | grep -v "bfx/.*/trivy-scan-results\.json$" || true)
          if [ -n "$NON_SCAN_FILES" ]; then
            echo "‚ö† WARNING: Non-scan-result files detected:"
            echo "$NON_SCAN_FILES"
            echo "Removing them from staging area..."
            echo "$NON_SCAN_FILES" | xargs git reset HEAD -- 2>/dev/null || true
          fi

          # Verify final staged files
          FINAL_STAGED=$(git diff --cached --name-only)
          echo "Final files to commit:"
          echo "$FINAL_STAGED"

          # Intelligent Change Detection
          echo ""
          echo "üîç Analyzing changes for intelligent PR creation..."
          
          CHANGE_TYPES=()
          CHANGE_DETAILS=()
          CRITICAL_COUNT=0
          HIGH_COUNT=0
          NEW_VERSIONS=()
          REMOVED_VERSIONS=()
          AFFECTED_TOOLS=()
          
          # Function to normalize JSON for comparison (exclude metadata)
          normalize_for_comparison() {
            local file="$1"
            jq -S 'del(.scan_timestamp, .workflow_run_id) | 
                   .versions | to_entries | 
                   map({
                     key: .key, 
                     value: {
                       image: .value.image,
                       vulnerabilities: (.value.vulnerabilities // []),
                       vulnerability_count: (.value.vulnerability_count // 0)
                     }
                   }) | 
                   from_entries' "$file" 2>/dev/null || echo "{}"
          }
          
          # Check each tool for changes
          for staged_file in $FINAL_STAGED; do
            if [[ "$staged_file" == bfx/*/trivy-scan-results.json ]]; then
              TOOL_NAME=$(echo "$staged_file" | sed 's|bfx/||' | sed 's|/trivy-scan-results.json||')
              echo "  ‚Üí Analyzing changes for: $TOOL_NAME"
              
              # Get current (new) content
              NEW_CONTENT=$(normalize_for_comparison "$staged_file")
              
              # Get previous content from main branch
              OLD_CONTENT=$(git show "main:$staged_file" 2>/dev/null | jq -S 'del(.scan_timestamp, .workflow_run_id) | 
                           .versions | to_entries | 
                           map({
                             key: .key, 
                             value: {
                               image: .value.image,
                               vulnerabilities: (.value.vulnerabilities // []),
                               vulnerability_count: (.value.vulnerability_count // 0)
                             }
                           }) | 
                           from_entries' 2>/dev/null || echo "{}")
              
              # Compare normalized content
              if [ "$NEW_CONTENT" != "$OLD_CONTENT" ]; then
                echo "    ‚úì Changes detected in $TOOL_NAME"
                AFFECTED_TOOLS+=("$TOOL_NAME")
                
                # Analyze type of changes
                NEW_VERSIONS_LIST=$(echo "$NEW_CONTENT" | jq -r 'keys[]' 2>/dev/null || echo "")
                OLD_VERSIONS_LIST=$(echo "$OLD_CONTENT" | jq -r 'keys[]' 2>/dev/null || echo "")
                
                # Check for new versions
                for version in $NEW_VERSIONS_LIST; do
                  if ! echo "$OLD_VERSIONS_LIST" | grep -q "^$version$"; then
                    NEW_VERSIONS+=("$TOOL_NAME:$version")
                    echo "    ‚Üí New version detected: $version"
                  fi
                done
                
                # Check for removed versions
                for version in $OLD_VERSIONS_LIST; do
                  if ! echo "$NEW_VERSIONS_LIST" | grep -q "^$version$"; then
                    REMOVED_VERSIONS+=("$TOOL_NAME:$version")
                    echo "    ‚Üí Version removed: $version"
                  fi
                done
                
                # Count vulnerability changes
                NEW_CRITICAL=$(jq '[.[] | .vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' <<< "$NEW_CONTENT" 2>/dev/null || echo "0")
                OLD_CRITICAL=$(jq '[.[] | .vulnerabilities[]? | select(.Severity == "CRITICAL")] | length' <<< "$OLD_CONTENT" 2>/dev/null || echo "0")
                NEW_HIGH=$(jq '[.[] | .vulnerabilities[]? | select(.Severity == "HIGH")] | length' <<< "$NEW_CONTENT" 2>/dev/null || echo "0")
                OLD_HIGH=$(jq '[.[] | .vulnerabilities[]? | select(.Severity == "HIGH")] | length' <<< "$OLD_CONTENT" 2>/dev/null || echo "0")
                
                CRITICAL_DIFF=$((NEW_CRITICAL - OLD_CRITICAL))
                HIGH_DIFF=$((NEW_HIGH - OLD_HIGH))
                
                if [ $CRITICAL_DIFF -ne 0 ]; then
                  CRITICAL_COUNT=$((CRITICAL_COUNT + CRITICAL_DIFF))
                  echo "    ‚Üí CRITICAL vulnerabilities changed: $CRITICAL_DIFF"
                fi
                
                if [ $HIGH_DIFF -ne 0 ]; then
                  HIGH_COUNT=$((HIGH_COUNT + HIGH_DIFF))
                  echo "    ‚Üí HIGH vulnerabilities changed: $HIGH_DIFF"
                fi
              else
                echo "    ‚è≠ No meaningful changes in $TOOL_NAME (metadata only)"
              fi
            fi
          done
          
          # Determine change types
          if [ $CRITICAL_COUNT -ne 0 ] || [ $HIGH_COUNT -ne 0 ]; then
            CHANGE_TYPES+=("vulnerabilities")
            if [ $CRITICAL_COUNT -gt 0 ]; then
              CHANGE_DETAILS+=("$CRITICAL_COUNT new CRITICAL vulnerabilities")
            elif [ $CRITICAL_COUNT -lt 0 ]; then
              CHANGE_DETAILS+=("$((CRITICAL_COUNT * -1)) CRITICAL vulnerabilities resolved")
            fi
            if [ $HIGH_COUNT -gt 0 ]; then
              CHANGE_DETAILS+=("$HIGH_COUNT new HIGH vulnerabilities")
            elif [ $HIGH_COUNT -lt 0 ]; then
              CHANGE_DETAILS+=("$((HIGH_COUNT * -1)) HIGH vulnerabilities resolved")
            fi
          fi
          
          if [ ${#NEW_VERSIONS[@]} -gt 0 ]; then
            CHANGE_TYPES+=("new-versions")
            CHANGE_DETAILS+=("${#NEW_VERSIONS[@]} new container versions")
          fi
          
          if [ ${#REMOVED_VERSIONS[@]} -gt 0 ]; then
            CHANGE_TYPES+=("removed-versions")
            CHANGE_DETAILS+=("${#REMOVED_VERSIONS[@]} versions removed")
          fi
          
          # Decision: Create PR or not?
          if [ ${#CHANGE_TYPES[@]} -gt 0 ]; then
            echo ""
            echo "üìã Change Summary:"
            echo "  ‚Üí Change types: ${CHANGE_TYPES[*]}"
            echo "  ‚Üí Tools affected: ${#AFFECTED_TOOLS[@]} (${AFFECTED_TOOLS[*]})"
            echo "  ‚Üí Details: ${CHANGE_DETAILS[*]}"
            echo "‚úÖ Meaningful changes detected - proceeding with PR creation"
            CREATE_PR=true
          else
            echo ""
            echo "‚úÖ No meaningful changes detected (metadata only)"
            echo "üìä Scan completed successfully:"
            echo "  ‚Üí Tools scanned: $COPIED_FILES"
            echo "  ‚Üí Files updated: metadata only"
            echo "‚è≠ Skipping PR creation"
            CREATE_PR=false
          fi

          # Set outputs for next steps
          echo "create-pr=$CREATE_PR" >> $GITHUB_OUTPUT
          echo "critical-count=$CRITICAL_COUNT" >> $GITHUB_OUTPUT
          echo "high-count=$HIGH_COUNT" >> $GITHUB_OUTPUT
          echo "affected-tools=$(IFS=','; echo "${AFFECTED_TOOLS[*]}")" >> $GITHUB_OUTPUT
          echo "change-types=$(IFS=','; echo "${CHANGE_TYPES[*]}")" >> $GITHUB_OUTPUT
          echo "change-details=$(IFS=','; echo "${CHANGE_DETAILS[*]}")" >> $GITHUB_OUTPUT
          echo "new-versions=$(IFS=','; echo "${NEW_VERSIONS[*]}")" >> $GITHUB_OUTPUT
          echo "removed-versions=$(IFS=','; echo "${REMOVED_VERSIONS[*]}")" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: steps.organize-results.outputs.tool-count > 0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ORGANIZED_DIR="${{ steps.organize-results.outputs.organized-dir }}"
          TOOL_COUNT="${{ steps.organize-results.outputs.tool-count }}"
          BRANCH_NAME="trivy-security-scan-$(date +%Y-%m-%d)"
          COPIED_FILES="${{ steps.organize-results.outputs.tool-count }}"
          CREATE_PR="${{ steps.analyze-changes.outputs.create-pr }}"

          # Commit changes (always commit for audit trail)
          echo ""
          echo "üíæ Committing changes for audit trail..."
          COMMIT_MSG="Update Trivy security scan results - $(date +%Y-%m-%d)"$'\n\n'"- Updated security scan results for $COPIED_FILES tools"$'\n'"- Scanned container images for CRITICAL and HIGH vulnerabilities"$'\n'"- Results include vulnerability details and counts per version"$'\n'"- Automated scan performed by Trivy Security Scan workflow"
          git commit -m "$COMMIT_MSG"

          # Push branch with explicit handling
          echo "üì§ Pushing branch: $BRANCH_NAME"

          # Try normal push first
          if git push origin "$BRANCH_NAME" 2>/dev/null; then
            echo "‚úÖ Branch pushed successfully"
          else
            echo "‚ö† Normal push failed, trying force push (branch may exist on remote)"
            echo "üîÑ Force pushing to update existing branch..."
            
            if git push --force-with-lease origin "$BRANCH_NAME"; then
              echo "‚úÖ Branch force-pushed successfully"
            else
              echo "‚úó Failed to push branch even with force"
              echo "This might be due to workflow file permissions or branch protection"
              echo "Checking what files are in the commit..."
              git show --name-only HEAD
              exit 1
            fi
          fi


          
      - name: Create intelligent pull request
        if: steps.analyze-changes.outputs.create-pr == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ORGANIZED_DIR="${{ steps.organize-results.outputs.organized-dir }}"
          BRANCH_NAME="trivy-security-scan-$(date +%Y-%m-%d)"
          COPIED_FILES="${{ steps.organize-results.outputs.tool-count }}"
          
          # Get change analysis results
          CRITICAL_COUNT="${{ steps.analyze-changes.outputs.critical-count }}"
          HIGH_COUNT="${{ steps.analyze-changes.outputs.high-count }}"
          AFFECTED_TOOLS="${{ steps.analyze-changes.outputs.affected-tools }}"
          CHANGE_TYPES="${{ steps.analyze-changes.outputs.change-types }}"
          CHANGE_DETAILS="${{ steps.analyze-changes.outputs.change-details }}"
          NEW_VERSIONS="${{ steps.analyze-changes.outputs.new-versions }}"
          REMOVED_VERSIONS="${{ steps.analyze-changes.outputs.removed-versions }}"
          
          # Convert comma-separated strings back to arrays
          IFS=',' read -ra AFFECTED_TOOLS_ARRAY <<< "$AFFECTED_TOOLS"
          IFS=',' read -ra CHANGE_TYPES_ARRAY <<< "$CHANGE_TYPES"
          IFS=',' read -ra CHANGE_DETAILS_ARRAY <<< "$CHANGE_DETAILS"
          IFS=',' read -ra NEW_VERSIONS_ARRAY <<< "$NEW_VERSIONS"
          IFS=',' read -ra REMOVED_VERSIONS_ARRAY <<< "$REMOVED_VERSIONS"

          # Update audit trail
          echo "üìù Updating security scan audit trail..."
          AUDIT_FILE=".github/security-scan-audit.json"
          CURRENT_TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          
          # Create or update audit trail
          if [ ! -f "$AUDIT_FILE" ]; then
            echo '{"scan_history": [], "tools_last_scanned": {}}' > "$AUDIT_FILE"
          fi
          
          # Add current scan to history
          SCAN_ENTRY=$(jq -n \
            --arg timestamp "$CURRENT_TIMESTAMP" \
            --arg run_id "${{ github.run_id }}" \
            --argjson tools_scanned "$COPIED_FILES" \
            --argjson changes_detected true \
            --argjson pr_created true \
            --arg affected_tools "$AFFECTED_TOOLS" \
            --arg change_types "$CHANGE_TYPES" \
            '{
              timestamp: $timestamp,
              run_id: $run_id,
              tools_scanned: $tools_scanned,
              changes_detected: $changes_detected,
              pr_created: $pr_created,
              affected_tools: ($affected_tools | split(",")),
              change_types: ($change_types | split(","))
            }')
          
          # Update audit file
          jq --argjson entry "$SCAN_ENTRY" \
             --arg timestamp "$CURRENT_TIMESTAMP" \
             --arg run_id "${{ github.run_id }}" \
             '.last_scan_timestamp = $timestamp |
              .last_scan_run_id = $run_id |
              .scan_history += [$entry] |
              .scan_history = (.scan_history | sort_by(.timestamp) | .[-50:])' \
             "$AUDIT_FILE" > "${AUDIT_FILE}.tmp" && mv "${AUDIT_FILE}.tmp" "$AUDIT_FILE"
          
          # Update tools last scanned
          for tool in "${AFFECTED_TOOLS_ARRAY[@]}"; do
            if [ -n "$tool" ]; then
              jq --arg tool "$tool" --arg timestamp "$CURRENT_TIMESTAMP" \
                 '.tools_last_scanned[$tool] = $timestamp' \
                 "$AUDIT_FILE" > "${AUDIT_FILE}.tmp" && mv "${AUDIT_FILE}.tmp" "$AUDIT_FILE"
            fi
          done
          
          # Add audit file to commit
          git add "$AUDIT_FILE"
          
          # Conditional PR creation logic
          echo ""
          echo "üìù Creating intelligent PR with change analysis..."
            echo ""
            echo "üìù Creating intelligent PR with change analysis..."
            
            # Generate smart PR title
            if [[ " $CHANGE_TYPES " =~ " vulnerabilities " ]]; then
              if [ $CRITICAL_COUNT -gt 0 ]; then
                PR_TITLE="üö® CRITICAL vulnerabilities detected in ${#AFFECTED_TOOLS_ARRAY[@]} tools - $(date +%Y-%m-%d)"
              elif [ $HIGH_COUNT -gt 0 ]; then
                PR_TITLE="‚ö†Ô∏è HIGH vulnerabilities detected in ${#AFFECTED_TOOLS_ARRAY[@]} tools - $(date +%Y-%m-%d)"
              else
                PR_TITLE="‚úÖ Vulnerabilities resolved in ${#AFFECTED_TOOLS_ARRAY[@]} tools - $(date +%Y-%m-%d)"
              fi
            elif [[ " $CHANGE_TYPES " =~ " new-versions " ]]; then
              PR_TITLE="üì¶ New container versions scanned - $(date +%Y-%m-%d)"
            elif [[ " $CHANGE_TYPES " =~ " removed-versions " ]]; then
              PR_TITLE="üóëÔ∏è Container versions removed - $(date +%Y-%m-%d)"
            else
              PR_TITLE="üîÑ Security scan results updated - $(date +%Y-%m-%d)"
            fi
            
            # Generate detailed PR body
            PR_BODY="## üîí Security Scan Results - $(date +%Y-%m-%d)"
            PR_BODY="$PR_BODY"$'\n\n'"### üìä Change Summary"
            PR_BODY="$PR_BODY"$'\n'"- **Change Types**: $CHANGE_TYPES"
            PR_BODY="$PR_BODY"$'\n'"- **Tools Affected**: ${#AFFECTED_TOOLS_ARRAY[@]} tools ($AFFECTED_TOOLS)"
            PR_BODY="$PR_BODY"$'\n'"- **Details**: $CHANGE_DETAILS"

            # Add vulnerability section if applicable
            if [[ " $CHANGE_TYPES " =~ " vulnerabilities " ]]; then
              PR_BODY="$PR_BODY"$'\n\n'"### üö® Vulnerability Changes"
              if [ $CRITICAL_COUNT -gt 0 ]; then
                PR_BODY="$PR_BODY"$'\n'"- **CRITICAL**: +$CRITICAL_COUNT new vulnerabilities ‚ö†Ô∏è **Immediate action required**"
              elif [ $CRITICAL_COUNT -lt 0 ]; then
                PR_BODY="$PR_BODY"$'\n'"- **CRITICAL**: $((CRITICAL_COUNT * -1)) vulnerabilities resolved ‚úÖ"
              fi
              
              if [ $HIGH_COUNT -gt 0 ]; then
                PR_BODY="$PR_BODY"$'\n'"- **HIGH**: +$HIGH_COUNT new vulnerabilities ‚ö†Ô∏è **Plan updates within 30 days**"
              elif [ $HIGH_COUNT -lt 0 ]; then
                PR_BODY="$PR_BODY"$'\n'"- **HIGH**: $((HIGH_COUNT * -1)) vulnerabilities resolved ‚úÖ"
              fi
            fi
            
            # Add version changes section if applicable
            if [ ${#NEW_VERSIONS_ARRAY[@]} -gt 0 ]; then
              PR_BODY="$PR_BODY"$'\n\n'"### üì¶ New Versions Scanned"
              for version_info in "${NEW_VERSIONS_ARRAY[@]}"; do
                if [ -n "$version_info" ]; then
                  PR_BODY="$PR_BODY"$'\n'"- **${version_info%:*}**: Added version \`${version_info#*:}\`"
                fi
              done
            fi
            
            if [ ${#REMOVED_VERSIONS_ARRAY[@]} -gt 0 ]; then
              PR_BODY="$PR_BODY"$'\n\n'"### üóëÔ∏è Versions Removed"
              for version_info in "${REMOVED_VERSIONS_ARRAY[@]}"; do
                if [ -n "$version_info" ]; then
                  PR_BODY="$PR_BODY"$'\n'"- **${version_info%:*}**: Removed version \`${version_info#*:}\`"
                fi
              done
            fi
            
            PR_BODY="$PR_BODY"$'\n\n'"### üìà Scan Statistics"
            PR_BODY="$PR_BODY"$'\n'"- **Tools Scanned**: $COPIED_FILES"
            if [ "${{ steps.prepare-recent.outputs.successful-scans }}" -gt 0 ]; then
              PR_BODY="$PR_BODY"$'\n'"- **Scan Duration**: ~30 seconds (artifact reuse)"
            else
              PR_BODY="$PR_BODY"$'\n'"- **Scan Duration**: ~2-3 hours (fresh scan)"
            fi
            PR_BODY="$PR_BODY"$'\n'"- **Workflow Run**: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})"
            
            PR_BODY="$PR_BODY"$'\n\n'"### üìã Next Steps"
            if [ $CRITICAL_COUNT -gt 0 ]; then
              PR_BODY="$PR_BODY"$'\n'"1. **üö® URGENT**: Review CRITICAL vulnerabilities immediately"
              PR_BODY="$PR_BODY"$'\n'"2. **üìã Plan**: Schedule container updates for affected versions"
              PR_BODY="$PR_BODY"$'\n'"3. **üîÑ Update**: Rebuild containers with security patches"
              PR_BODY="$PR_BODY"$'\n'"4. **‚úÖ Verify**: Re-run scan after updates"
            elif [ $HIGH_COUNT -gt 0 ]; then
              PR_BODY="$PR_BODY"$'\n'"1. **üìã Review**: Assess HIGH vulnerabilities within 30 days"
              PR_BODY="$PR_BODY"$'\n'"2. **üìÖ Plan**: Schedule container updates"
              PR_BODY="$PR_BODY"$'\n'"3. **üîÑ Update**: Apply security patches"
              PR_BODY="$PR_BODY"$'\n'"4. **‚úÖ Merge**: Merge this PR to update security baseline"
            else
              PR_BODY="$PR_BODY"$'\n'"1. **üëÄ Review**: Check the updated scan results"
              PR_BODY="$PR_BODY"$'\n'"2. **‚úÖ Merge**: Merge this PR to update security baseline"
            fi
            
            PR_BODY="$PR_BODY"$'\n\n'"---"
            PR_BODY="$PR_BODY"$'\n'"*ü§ñ Automated security scan ‚Ä¢ Assigned to @gkr0110 for review*"
            PR_BODY="$PR_BODY"$'\n'"*üìä Audit trail updated in \`.github/security-scan-audit.json\`*"
          
          else
            echo ""
            echo "‚è≠ No PR creation needed - audit trail updated"
            echo "üìä Scan summary:"
            echo "  ‚Üí Tools scanned: $COPIED_FILES"
            echo "  ‚Üí Changes detected: None (metadata only)"
            echo "  ‚Üí Audit trail: Updated with scan timestamp"
            echo "  ‚Üí Next scan: Will reuse these results if no changes"
            
      - name: Handle no PR creation case
        if: steps.analyze-changes.outputs.create-pr == 'false'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BRANCH_NAME="trivy-security-scan-$(date +%Y-%m-%d)"
          COPIED_FILES="${{ steps.organize-results.outputs.tool-count }}"
          
          # Update audit trail for no-PR case
          echo "üìù Updating security scan audit trail..."
          AUDIT_FILE=".github/security-scan-audit.json"
          CURRENT_TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          
          # Create or update audit trail
          if [ ! -f "$AUDIT_FILE" ]; then
            echo '{"scan_history": [], "tools_last_scanned": {}}' > "$AUDIT_FILE"
          fi
          
          # Add current scan to history
          SCAN_ENTRY=$(jq -n \
            --arg timestamp "$CURRENT_TIMESTAMP" \
            --arg run_id "${{ github.run_id }}" \
            --argjson tools_scanned "$COPIED_FILES" \
            --argjson changes_detected false \
            --argjson pr_created false \
            '{
              timestamp: $timestamp,
              run_id: $run_id,
              tools_scanned: $tools_scanned,
              changes_detected: $changes_detected,
              pr_created: $pr_created,
              affected_tools: [],
              change_types: []
            }')
          
          # Update audit file
          jq --argjson entry "$SCAN_ENTRY" \
             --arg timestamp "$CURRENT_TIMESTAMP" \
             --arg run_id "${{ github.run_id }}" \
             '.last_scan_timestamp = $timestamp |
              .last_scan_run_id = $run_id |
              .scan_history += [$entry] |
              .scan_history = (.scan_history | sort_by(.timestamp) | .[-50:])' \
             "$AUDIT_FILE" > "${AUDIT_FILE}.tmp" && mv "${AUDIT_FILE}.tmp" "$AUDIT_FILE"
          
          # Add audit file to commit
          git add "$AUDIT_FILE"
          
          # Still need to commit the audit trail
          COMMIT_MSG="Update security scan audit trail - $(date +%Y-%m-%d)"$'\n\n'"- Scanned $COPIED_FILES tools successfully"$'\n'"- No vulnerability changes detected (metadata only)"$'\n'"- Updated audit trail with scan timestamp"$'\n'"- Automated scan performed by Trivy Security Scan workflow"
          git commit --amend -m "$COMMIT_MSG"
          
          # Push the audit trail update
          if git push origin "$BRANCH_NAME" 2>/dev/null; then
            echo "‚úÖ Audit trail pushed successfully"
          else
            git push --force-with-lease origin "$BRANCH_NAME"
            echo "‚úÖ Audit trail force-pushed successfully"
          fi
          
          echo ""
          echo "üéâ Workflow completed successfully without PR"
          echo "‚úÖ All scan results preserved in artifacts"
          echo "üìù Audit trail maintained for compliance"

          # Create or update pull request
          echo "üìù Creating or updating pull request..."

          # Check if PR already exists for this branch
          EXISTING_PR=$(gh pr list --head "$BRANCH_NAME" --json number --jq '.[0].number' 2>/dev/null || echo "")

          if [ -n "$EXISTING_PR" ]; then
            echo "‚ö† Pull request already exists for branch $BRANCH_NAME (PR #$EXISTING_PR)"
            echo "üîÑ Updating existing pull request..."
            
            # Update the existing PR
            if gh pr edit "$EXISTING_PR" \
              --title "$PR_TITLE" \
              --body "$PR_BODY" \
              --add-assignee gkr0110; then
              echo "‚úÖ Pull request #$EXISTING_PR updated successfully"
              PR_IDENTIFIER="$EXISTING_PR"  # Use PR number for label operations
            else
              echo "‚úó Failed to update existing pull request"
              exit 1
            fi
          else
            echo "‚úÖ Creating new pull request..."
            if gh pr create \
              --title "$PR_TITLE" \
              --body "$PR_BODY" \
              --base main \
              --head "$BRANCH_NAME" \
              --assignee gkr0110; then
              echo "‚úÖ Pull request created successfully"
              PR_IDENTIFIER="$BRANCH_NAME"  # Use branch name for label operations
            else
              echo "‚úó Failed to create pull request"
              exit 1
            fi
          fi

          # Add smart labels based on change types
          echo "Adding intelligent labels based on changes..."
          
          # Always add base labels
          gh pr edit "$PR_IDENTIFIER" --add-label "security" 2>/dev/null && echo "  ‚úì Added 'security' label" || echo "  ‚ö† Could not add 'security' label (label may not exist)"
          gh pr edit "$PR_IDENTIFIER" --add-label "automated" 2>/dev/null && echo "  ‚úì Added 'automated' label" || echo "  ‚ö† Could not add 'automated' label (label may not exist)"
          gh pr edit "$PR_IDENTIFIER" --add-label "trivy-scan" 2>/dev/null && echo "  ‚úì Added 'trivy-scan' label" || echo "  ‚ö† Could not add 'trivy-scan' label (label may not exist)"
          
          # Add severity-based labels
          if [ $CRITICAL_COUNT -gt 0 ]; then
            gh pr edit "$PR_IDENTIFIER" --add-label "critical" 2>/dev/null && echo "  ‚úì Added 'critical' label" || echo "  ‚ö† Could not add 'critical' label (label may not exist)"
            gh pr edit "$PR_IDENTIFIER" --add-label "urgent" 2>/dev/null && echo "  ‚úì Added 'urgent' label" || echo "  ‚ö† Could not add 'urgent' label (label may not exist)"
          elif [ $HIGH_COUNT -gt 0 ]; then
            gh pr edit "$PR_IDENTIFIER" --add-label "high-priority" 2>/dev/null && echo "  ‚úì Added 'high-priority' label" || echo "  ‚ö† Could not add 'high-priority' label (label may not exist)"
          fi
          
          # Add change-type labels
          if [[ " $CHANGE_TYPES " =~ " new-versions " ]]; then
            gh pr edit "$PR_IDENTIFIER" --add-label "new-versions" 2>/dev/null && echo "  ‚úì Added 'new-versions' label" || echo "  ‚ö† Could not add 'new-versions' label (label may not exist)"
          fi
          
          if [[ " $CHANGE_TYPES " =~ " vulnerabilities " ]]; then
            gh pr edit "$PR_IDENTIFIER" --add-label "vulnerabilities" 2>/dev/null && echo "  ‚úì Added 'vulnerabilities' label" || echo "  ‚ö† Could not add 'vulnerabilities' label (label may not exist)"
          fi

          echo ""
          echo "üéâ Trivy Security Scan Workflow Completed Successfully!"
          echo "=============================================="
          echo "‚úÖ Scanned $COPIED_FILES tools with security results"
          echo "‚úÖ Created branch: $BRANCH_NAME"
          echo "‚úÖ Intelligent PR created/updated with meaningful changes"
          echo "‚úÖ Assigned to @gkr0110 for security review"
          echo "‚úÖ All artifacts preserved for future reuse"
          echo "‚úÖ Audit trail updated for compliance"
          echo ""
          echo "üìä Change Analysis:"
          echo "  ‚Üí Change types: $CHANGE_TYPES"
          echo "  ‚Üí Tools affected: ${#AFFECTED_TOOLS_ARRAY[@]}"
          echo "  ‚Üí Vulnerability impact: $CRITICAL_COUNT CRITICAL, $HIGH_COUNT HIGH"
          echo ""
          echo "üìã Next steps:"
          if [ $CRITICAL_COUNT -gt 0 ]; then
            echo "  üö® URGENT: Review CRITICAL vulnerabilities immediately"
            echo "  üìã Plan container updates for affected versions"
            echo "  üîÑ Rebuild containers with security patches"
          elif [ $HIGH_COUNT -gt 0 ]; then
            echo "  ‚ö†Ô∏è Review HIGH vulnerabilities within 30 days"
            echo "  üìÖ Plan container updates"
            echo "  üîÑ Apply security patches"
          else
            echo "  üëÄ Review the updated scan results"
          fi
          echo "  ‚úÖ Merge the PR to update security baseline"

          echo ""
          echo "‚úì Pull Request operation completed successfully"
          echo "  ‚Üí Branch: $BRANCH_NAME"
          echo "  ‚Üí Files updated: $COPIED_FILES"
          if command -v gh >/dev/null 2>&1; then
            PR_URL=$(gh pr view "$PR_IDENTIFIER" --json url -q .url 2>/dev/null || echo "URL not available")
            echo "  ‚Üí PR URL: $PR_URL"
          fi

      - name: Upload scan results as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trivy-scan-results
          path: |
            trivy-results/
            organized-results/
          retention-days: 90

    outputs:
      total-scanned: ${{ steps.batch-scan.outputs.total-scanned || steps.prepare-recent.outputs.total-scanned }}
      successful-scans: ${{ steps.batch-scan.outputs.successful-scans || steps.prepare-recent.outputs.successful-scans }}
      failed-scans: ${{ steps.batch-scan.outputs.failed-scans || steps.prepare-recent.outputs.failed-scans }}
      used-recent-results: ${{ steps.check-reuse.outputs.reuse-available }}
      tool-count: ${{ steps.organize-results.outputs.tool-count }}

  summary:
    name: Scan Summary
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [check-recent-scans, security-scan, trivy-scan]
    if: always()

    steps:
      - name: Display comprehensive scan summary
        run: |
          echo "Trivy Security Scan Workflow Complete"
          echo "======================================"
          echo "Workflow execution time: $(date)"
          echo ""

          # Discovery phase summary
          echo "üìã Discovery Phase:"
          if [ "${{ needs.security-scan.outputs.image-count }}" -gt 0 ]; then
            echo "  ‚úì Images discovered: ${{ needs.security-scan.outputs.image-count }}"
          else
            echo "  ‚ö† No container images found to scan"
            echo "    ‚Üí Verify images are published to ghcr.io with products/bfx/ prefix"
            echo "    ‚Üí Check repository permissions for package access"
          fi
          echo ""

          # Scanning phase summary
          echo "üîç Scanning Phase:"

          # Check if recent results were used
          if [ "${{ needs.trivy-scan.outputs.used-recent-results }}" == "true" ]; then
            echo "  üîÑ Used recent scan results (within last month)"
            echo "    ‚Üí Recent run ID: ${{ needs.check-recent-scans.outputs.recent-run-id }}"
            echo "    ‚Üí Skipped re-scanning to save time and resources"
            echo "    ‚Üí Results processed from previous successful scan"
          else
            echo "  üíæ Checkpoint/Resume System Active"
            echo "    ‚Üí Progress is saved after each successful scan"
            echo "    ‚Üí Failed runs can be resumed from last checkpoint"
            echo "    ‚Üí Use 'Resume from progress' option (enabled by default)"
          fi

          case "${{ needs.trivy-scan.result }}" in
            "success")
              if [ "${{ needs.trivy-scan.outputs.used-recent-results }}" == "true" ]; then
                echo "  ‚úì Recent scan results processed successfully"
              else
                echo "  ‚úì Batch scanning completed successfully"
              fi
              echo "  üìä Results:"
              echo "    ‚Üí Tools processed: ${{ needs.trivy-scan.outputs.tool-count }}"
              echo "    ‚Üí Images scanned: ${{ needs.trivy-scan.outputs.successful-scans }}"
              echo "    ‚Üí Failed scans: ${{ needs.trivy-scan.outputs.failed-scans }}"
              echo "  üìÅ Output:"
              echo "    ‚Üí JSON files created in bfx/<tool>/trivy-scan-results.json"
              echo "    ‚Üí Pull Request created with all results"
              ;;
            "failure")
              echo "  ‚úó Batch scanning encountered issues"
              echo "    ‚Üí Check individual scan logs in workflow details"
              ;;
            "skipped")
              echo "  ‚è≠ Scanning was skipped (no images to process)"
              ;;
            *)
              echo "  ‚ùì Scanning status: ${{ needs.trivy-scan.result }}"
              ;;
          esac
          echo ""

          # Next steps
          echo "üìã Next Steps:"
          if [ "${{ needs.trivy-scan.result }}" == "success" ]; then
            echo "  1. Review the created Pull Request with scan results"
            echo "  2. Check individual tool directories: bfx/<tool>/trivy-scan-results.json"
            echo "  3. Address any CRITICAL vulnerabilities found"
            echo "  4. Plan container image updates for affected versions"
            echo "  5. Merge the PR to update the security baseline"
          elif [ "${{ needs.security-scan.outputs.image-count }}" -eq 0 ]; then
            echo "  1. Verify container images are published to ghcr.io"
            echo "  2. Check that images follow the products/bfx/* naming pattern"
            echo "  3. Ensure workflow has proper permissions to access packages"
          else
            echo "  1. Review workflow logs for specific error details"
            echo "  2. Check network connectivity and registry access"
            echo "  3. Verify Trivy configuration and image accessibility"
            echo "  4. If scan was interrupted, re-run workflow to resume from progress"
          fi

          echo ""
          echo "üîÑ This workflow runs automatically on the first Sunday of every month"
          echo "   Manual execution: Use 'Run workflow' button in Actions tab"
